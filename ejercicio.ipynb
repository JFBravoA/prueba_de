{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b2d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6893e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://smn.conagua.gob.mx/webservices/?method=1'\n",
    "header = {'User-Agent': 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 \\\n",
    "          (KHTML, like Gecko) Mobile/15E148'}\n",
    "\n",
    "ruta_input = 'C:/Users/Usuario/Documents/data_municipios/'\n",
    "ruta_tablas = 'C:/Users/Usuario/Documents/prueba_de/outputs/tablas/'\n",
    "ruta_cruces = 'C:/Users/Usuario/Documents/prueba_de/outputs/tablas_cruzadas/'\n",
    "ruta_current = 'C:/Users/Usuario/Documents/prueba_de/outputs/current/'\n",
    "ruta_logs = 'C:/Users/Usuario/Documents/prueba_de/outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ec8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = f'{ruta_logs}logs.log',format = '%(asctime)s %(message)s',filemode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f87606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(url_1, header_1):\n",
    "    \n",
    "    logger_scraping = logging.getLogger()\n",
    "    \n",
    "    try:\n",
    "        result = requests.get(url_1, headers = header_1)\n",
    "        data = gzip.decompress(result.content)\n",
    "        data = json.loads(data)\n",
    "        data = pd.DataFrame(data)\n",
    "        data = data[['ides','idmun','prec','tmax','tmin']]\n",
    "\n",
    "        data['ides'] = data['ides'].astype(int)\n",
    "        data['idmun'] = data['idmun'].astype(int)\n",
    "        data['prec'] = data['prec'].astype(float)\n",
    "        data['tmax'] = data['tmax'].astype(float)\n",
    "        data['tmin'] = data['tmin'].astype(float)\n",
    "        \n",
    "        logger_scraping.setLevel(logging.INFO)\n",
    "        logger_scraping.info('Data extraída con éxito')\n",
    "\n",
    "        return data\n",
    "    \n",
    "    except:\n",
    "        logger_scraping.setLevel(logging.CRITICAL)\n",
    "        logger_scraping.critical('Hubo un error al extraer o descomprimir la data')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "i = 0\n",
    "count = 1\n",
    "\n",
    "while i <= n:\n",
    "    \n",
    "    data = getData(url, header)\n",
    "    data2 = pd.DataFrame()\n",
    "\n",
    "    if count % 2 == 0:\n",
    "\n",
    "        data2 = pd.concat([data, data2], ignore_index = True)\n",
    "        data_final = data2.groupby(['ides', 'idmun'], as_index = False).mean()\n",
    "        data_final.rename(columns = {'ides':'Cve_Ent', 'idmun':'Cve_Mun', 'prec':'prec_avg',\n",
    "                                    'tmax':'tmax_avg', 'tmin':'tmin_avg'}, inplace = True)\n",
    "        data_final['tavg'] = data_final[['tmax_avg','tmin_avg']].mean(axis = 1)\n",
    "\n",
    "        now = datetime.now()\n",
    "        now = now.strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "        data_final.to_csv(f'{ruta_tablas}{now}.csv')\n",
    "        \n",
    "        logger_data_avg = logging.getLogger()\n",
    "        logger_data_avg.setLevel(logging.INFO)\n",
    "        logger_data_avg.info('Data con promedios creada con éxito')\n",
    "\n",
    "        lista = os.listdir(ruta_input)\n",
    "        lista_fechas = []\n",
    "\n",
    "        for archivo in lista:\n",
    "\n",
    "            anio = archivo[:4]\n",
    "            mes = archivo[4:6]\n",
    "            dia = archivo[6:8]\n",
    "\n",
    "            date_archivo = pd.to_datetime(f'{anio}-{mes}-{dia}')\n",
    "            date_archivo = date_archivo.date()\n",
    "\n",
    "            lista_fechas.append(date_archivo)\n",
    "\n",
    "        reciente = max(lista_fechas)\n",
    "\n",
    "        id_reciente = int(str(reciente).split('-')[0] + str(reciente).split('-')[1] + str(reciente).split('-')[2])\n",
    "\n",
    "        data_municipios = pd.read_csv(f'{ruta_input}/{id_reciente}/data.csv')\n",
    "        data_municipios = data_municipios.merge(data_final, how = 'left')   \n",
    "        data_municipios.fillna(0, inplace = True)\n",
    "\n",
    "        data_municipios.to_csv(f'{ruta_cruces}/{now}.csv', index = False)\n",
    "        data_municipios.to_csv(f'{ruta_current}/current.csv', index = False)\n",
    "        \n",
    "        logger_data_cruce = logging.getLogger()\n",
    "        logger_data_cruce.setLevel(logging.INFO)\n",
    "        logger_data_cruce.info('Data cruzada con éxito')\n",
    "\n",
    "        del data, data2, data_final, data_municipios\n",
    "        \n",
    "        \n",
    "        time.sleep(60)\n",
    "\n",
    "    else: \n",
    "        data2 = pd.concat([data, data2], ignore_index = True)\n",
    "        time.sleep(60)\n",
    "\n",
    "    i += 1\n",
    "    count += 1    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
